{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Model and The Dataset Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we develop the next step in our GNN model. To apply either the _meta-layer_ approch or the  or the _ParticleNet_ approch we need to first have a graph structure in hand. \n",
    "\n",
    "Comming up with direct mehods to make a graph structure from the processed event data is not encouraged, considering the huge number of hits / nodes ($\\approx 10^6$). Direct method's like compaeing distances and angles are computatinally expensive. Insted we train a multylayer perceptron (MLP) in such a way so that points belonging to the same track are close in the latent space, which will allow us to apply a effective knn algorithm to construct the graph strcuture. \n",
    "This intermidiate ML model is reffered to as the embeddding model. [1]\n",
    "\n",
    "[1] : Ju, Xiangyang, et al. \"Performance of a geometric deep learning pipeline for HL-LHC particle tracking.\" The European Physical Journal C 81 (2021): 1-14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.6.0\n",
      "PyG version 2.6.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import ortho_group\n",
    "\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.linalg import norm \n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, ReLU, BatchNorm1d, Module, Sequential\n",
    "from torch import Tensor\n",
    "\n",
    "# torch.set_default_dtype(torch.float64)\n",
    "\n",
    "from torch_geometric.typing import (\n",
    "    Adj,\n",
    "    OptPairTensor,\n",
    "    OptTensor,\n",
    "    Size,\n",
    "    SparseTensor,\n",
    "    torch_sparse,\n",
    ")\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Batch\n",
    "import torch_geometric.transforms as T\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch_geometric.utils import remove_self_loops, to_dense_adj, dense_to_sparse, is_undirected , to_undirected, contains_self_loops , to_networkx\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool, knn_graph\n",
    "from torch_geometric.datasets import QM9\n",
    "# from torch_scatter import scatter\n",
    "# from torch_cluster import knn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "# import uproot\n",
    "import vector\n",
    "vector.register_awkward()\n",
    "import awkward as ak\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 5 \n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrackML import Preprocessing\n",
    "from TrackML.Models.utils import buildMLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set default params for matplotlib : \n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define Point Cloud Class for Processed Data \n",
    "We define a point cloud dataset class to train our embedding model with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_path = '../data/detectors.csv'\n",
    "dataset_path = '../data/train_100_events/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudData(data.Dataset): \n",
    "    \n",
    "    # initialize the dataset class : \n",
    "    def __init__(self,dataset_path:str,detector_path:str,min_nhits=3)->None:\n",
    "        '''\n",
    "        dataset_path : path to the dataset with the events. \n",
    "        eventids : list of eventid identifiers. \n",
    "        '''\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dataset_path = dataset_path\n",
    "        self.min_nhits = min_nhits \n",
    "        \n",
    "        \n",
    "        self.detector = Preprocessing.load_detector_data(detector_path) \n",
    "        \n",
    "        # get the list of event ids from the dataset folder : \n",
    "        eventids = [ code[:-9] for code in os.listdir(dataset_path) if code.endswith('-hits.csv') ]\n",
    "        self.eventids = eventids\n",
    "        \n",
    "        \n",
    "    def __len__(self)->int: \n",
    "        return len( self.eventids )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            Preprocessing.process_event_data(\n",
    "                train_path=self.dataset_path, \n",
    "                eventid=self.eventids[index], \n",
    "                detector=self.detector\n",
    "            ), \n",
    "            Preprocessing.process_particle_labels(\n",
    "                train_path=self.dataset_path, \n",
    "                eventid=self.eventids[index], \n",
    "                min_nhits=self.min_nhits \n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_cloud_dataset = PointCloudData(dataset_path,detector_path)\n",
    "len(point_cloud_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_function(data_list:list): \n",
    "    # since we only indend to use batch size of 1 \n",
    "    # for the embedding layer.\n",
    "    return data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the data loader object ! \n",
    "point_clout_data_loder = data.DataLoader(\n",
    "    dataset=point_cloud_dataset, \n",
    "    batch_size=1, \n",
    "    shuffle=True , \n",
    "    collate_fn=collate_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([120246, 15]), torch.Size([120246]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_feats , labels  = next(iter(point_clout_data_loder))\n",
    "node_feats.shape , labels.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create the Base Embedding Model.\n",
    "\n",
    "The model architecture is just a normal MLP with relu acctivation for hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModel(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features:int, \n",
    "        hidden_features:list, \n",
    "        out_features:int \n",
    "    )->None:\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # define the MLP layer : \n",
    "        self.MLP = buildMLP(\n",
    "            insize=in_features, \n",
    "            outsize=out_features, \n",
    "            features=hidden_features,\n",
    "            add_bnorm=False\n",
    "        )\n",
    "        \n",
    "    def forward(self,x:Tensor)->Tensor: \n",
    "        out =  self.MLP(x)\n",
    "        out = (out - out.mean(dim=0,keepdim=True))/out.std(dim=0,keepdim=True)\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingModel(\n",
       "  (MLP): Sequential(\n",
       "    (0): Linear(in_features=15, out_features=20, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=20, out_features=25, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=25, out_features=15, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=15, out_features=10, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=10, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_embedding_model = EmbeddingModel(\n",
    "    in_features=15, \n",
    "    hidden_features=[20,25,15,10],\n",
    "    out_features=5\n",
    ")\n",
    "example_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_feats.mean(dim=0 , keepdim=True).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120246, 15])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(node_feats/node_feats.std(dim=0 , keepdim=True)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120246, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_model_out = example_embedding_model(node_feats)\n",
    "example_model_out.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Latent Space Analysis \n",
    "\n",
    "Here we create a graph structure by using a _radius\\_graph_ algorithm, on the latent space featuers. We set the radius hyperparameter same as the margin for our pairwise hinge loss function (more on that later). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1442077])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margin = .1\n",
    "max_num_neighbors=12\n",
    "\n",
    "radius_graph_edge_index = torch_geometric.nn.pool.radius_graph(\n",
    "    example_model_out, \n",
    "    r = margin , \n",
    "    loop = False , \n",
    "    max_num_neighbors=max_num_neighbors\n",
    ")\n",
    "radius_graph_edge_index\n",
    "radius_graph_edge_index.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120246, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_model_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the graph is undirected \n",
    "is_undirected( radius_graph_edge_index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1894982])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the graph to a directed one \n",
    "radius_graph_edge_index = to_undirected( radius_graph_edge_index )\n",
    "radius_graph_edge_index.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now each pair had a duplicate copy in the indices list, \n",
    "# since the graph is undirected now. \n",
    "row , col = radius_graph_edge_index\n",
    "\n",
    "# Create a mask to get those pairs which have different \n",
    "# labels and avoid repeations by choosing row < col\n",
    "mask = ( row < col ) & ( labels[row] != labels[col] )\n",
    "\n",
    "negetive_pair_indices = radius_graph_edge_index[:,mask]\n",
    "del mask , row , col "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 893179])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negetive_pair_indices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create Custom Loss Function: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use pairwise hinge loss functions on all pairs of the hits. For this we use the Hinge Loss (`torch.nn.HingeEmbeddingLoss` see [documentation](https://pytorch.org/docs/stable/generated/torch.nn.HingeEmbeddingLoss.html#torch.nn.HingeEmbeddingLoss)). \n",
    "\n",
    "The loss function is given as: \n",
    "$$\n",
    "l_n = \\begin{cases}\n",
    "    x_n, &\\text{ if } y_n = 1 \\\\\n",
    "    max\\{0,\\text{margin}-x_n\\}, &\\text{ if } y_n = -1 \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Note that we cannot afford to calculate pairwise distance for all the hit pairs in the latent space, since that is computationally too expenceive. Insted we calculate the loss using a trick to optimize the calculation. \n",
    "\n",
    "We seperately calculate the loss for all the correct hit pairs and calculate the loss for all the incorrect hit pairs that are formed post a knn cluster calculation. This way we avoid the redundent zeros that come up in direct pairwise loss calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pair_indices = Preprocessing.get_track_index_pairs(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 538549]), torch.Size([2, 893179]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_pair_indices.shape , negetive_pair_indices.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0342, 0.0725, 0.1242,  ..., 0.2918, 0.3060, 0.0141],\n",
      "       grad_fn=<LinalgVectorNormBackward0>) tensor([0.0114, 0.0049, 0.0026,  ..., 0.0011, 0.0074, 0.0239],\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(922966.8125, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prow , pcol = positive_pair_indices  \n",
    "nrow , ncol = negetive_pair_indices\n",
    "\n",
    "# since the arry sizes are too large we apply batching for \n",
    "# pairwise distance calculations: \n",
    "\n",
    "loss_plus = norm(\n",
    "    example_model_out[prow , : ] - example_model_out[pcol, :] , \n",
    "    ord = 2 , \n",
    "    dim = -1 \n",
    ")\n",
    "\n",
    "loss_minus = norm(\n",
    "    example_model_out[ncol,:] - example_model_out[nrow,:], \n",
    "    ord = 2 , \n",
    "    dim = -1 \n",
    ")\n",
    "\n",
    "print( loss_plus , loss_minus )\n",
    "\n",
    "loss = (margin - loss_minus).sum() + loss_plus.sum()\n",
    "\n",
    "loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EmbeddingLossFunction(\n",
    "        x:Tensor,\n",
    "        labels:Tensor,\n",
    "        radius_graph_edge_index:Tensor,\n",
    "        margin:float=1\n",
    "    )->Tensor: \n",
    "    '''\n",
    "    x  : model output in the latent space. shape = [nhits, out_feats]\n",
    "    radius_graph_edge_index : graph formed with the radius ball algorithm. \n",
    "    positive_idx : pairs of indices of hits sharing the same \n",
    "        particle id. shape = [2,num_positive_pairs]. \n",
    "    negetive_idx : pairs of hits indices within the latent space \n",
    "        margin radius ball having different particle ids. \n",
    "    returns : the pair wise hinge loss. \n",
    "    '''\n",
    "    \n",
    "    radius_graph_edge_index = to_undirected( radius_graph_edge_index )\n",
    "    \n",
    "    # get the positive indices \n",
    "    positive_idx = Preprocessing.get_track_index_pairs(labels)\n",
    "    \n",
    "    # get the negetive indices pairs that lie within the margin ball : \n",
    "    row , col = radius_graph_edge_index\n",
    "\n",
    "    # Create a mask to get those pairs which have different \n",
    "    # labels and avoid repeations by choosing row < col\n",
    "    mask = ( row < col ) & ( labels[row] != labels[col] )\n",
    "    negetive_idx = radius_graph_edge_index[:,mask]\n",
    "    \n",
    "    # get the positive row and col idx : \n",
    "    prow , pcol = positive_idx \n",
    "    \n",
    "    # get the negetive row and col idx : \n",
    "    nrow , ncol = negetive_idx\n",
    "    \n",
    "    # loss form the positive pairs \n",
    "    loss_plus = norm(\n",
    "    x[prow , : ] - x[pcol, :] , \n",
    "    ord = 2 , \n",
    "    dim = -1 \n",
    "    )\n",
    "\n",
    "    # distance between negetive pairs that lie within the margin\n",
    "    loss_minus = norm(\n",
    "        x[ncol,:] - x[nrow,:], \n",
    "        ord = 2 , \n",
    "        dim = -1 \n",
    "    )\n",
    "    \n",
    "    # final loss \n",
    "    loss = (margin - loss_minus).sum() + loss_plus.sum()\n",
    "\n",
    "    return loss     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Define Graph Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use knn statergy in the latent space to create graph structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_graph_structure(latent_space_hits:Tensor,k:int): \n",
    "#     return torch_geometric.nn.pool.knn_graph(x = latent_space_hits, k = k )\n",
    "\n",
    "# k=5 \n",
    "# example_edge_indeces = create_graph_structure(example_model_out,k=k)\n",
    "# example_edge_indeces.shape \n",
    "\n",
    "# get PyG grapg data structure for the knn buil graph. \n",
    "example_graph_data = Data(\n",
    "    x = node_feats, \n",
    "    edge_index=radius_graph_edge_index, \n",
    "    y = labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "from networkx import connected_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disconnected_components(data:Data):\n",
    "    # Convert PyG graph to NetworkX graph\n",
    "    G = to_networkx(data, to_undirected=True)\n",
    "    \n",
    "    # Get connected components\n",
    "    component_list = list(connected_components(G))\n",
    "    \n",
    "    # Convert node indices back to PyTorch tensors\n",
    "    components = [torch.tensor(list(component)) for component in component_list]\n",
    "    \n",
    "    return components\n",
    "\n",
    "example_components = get_disconnected_components(example_graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3644, torch.Size([9388]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( example_components ),torch.unique(labels).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(4509921819230208), tensor(15))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get one of these component for metric analysis \n",
    "example_component = example_components[0]\n",
    "print(example_component.shape)\n",
    "\n",
    "# find the majority particle id that belong to this track: \n",
    "component_labels = labels[example_component]\n",
    "mode , count = torch.mode( component_labels )\n",
    "mode , count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3644, 3644)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accociateed particle with each disconnectde component of the graph : \n",
    "accociated_particle = [ torch.mode(labels[component])[0] for component in example_components]\n",
    "len(accociated_particle) , len(example_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Define Track Metrics\n",
    "\n",
    "for detais of the metrices used, see [1]. \n",
    "\n",
    "[1] Ju, Xiangyang, et al. \"Performance of a geometric deep learning pipeline for HL-LHC particle tracking.\" The European Physical Journal C 81 (2021): page 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_reconstruction_metrics( graph_data:Data , labels:Tensor )->tuple: \n",
    "    '''\n",
    "        data : graph dataset to get the metrics for : \n",
    "        labels : particle_ids for each of the nodes (hits)\n",
    "        returns : the trajecteory and particle purity of the graph dataset. \n",
    "    '''\n",
    "    \n",
    "    # get the disconnected compoenents (reconstructed tracks) form the graph steructure : \n",
    "    disconnected_components = get_disconnected_components(graph_data)\n",
    "    \n",
    "    \n",
    "    ## 1. get the matched partices for each of the disconnecte graphs : \n",
    "    \n",
    "    #  partices with the max occourence for each of the disconnected components : \n",
    "    max_track_particle = torch.tensor([ torch.mode(labels[component])[0] for component in disconnected_components])\n",
    "    \n",
    "    # frequency of the particle with the most occourence for each of the disconnected component : \n",
    "    max_track_particle_freq = torch.tensor([ torch.sum(track == particle) for particle,track in zip(max_track_particle,disconnected_components)])\n",
    "    \n",
    "    # get the number of hits that belong to each reconstructed track : \n",
    "    num_hits_tracks = torch.tensor( [component.shape[0] for component in disconnected_components] )\n",
    "    \n",
    "    # keep mark for each reconstructed track for which the particle \n",
    "    # with the most occourance, makes for at least 50% of all the hits in \n",
    "    # the given reconstructed track. \n",
    "    # we also exclude particle's with id 0 \n",
    "    \n",
    "    mask = ( 2*max_track_particle_freq >= num_hits_tracks ) & ( max_track_particle != 0 )\n",
    "    \n",
    "    # total number of true hits left by the underlying max_track_particle : \n",
    "    max_track_particle_num_true_hits = torch.tensor([torch.sum(labels==particle) for particle in max_track_particle])\n",
    "    \n",
    "    # update the mark, now slelecting the tracks such that at\n",
    "    # least 50% of the max occurance particles true hits\n",
    "    # must be contained in the reconstructed graph. \n",
    "    mask = mask & ( 2*max_track_particle_freq >= max_track_particle_num_true_hits )\n",
    "    \n",
    "    # with this we can how get the matched reconstructed \n",
    "    # tracks and corresponding matched particles \n",
    "    matched_tracks = [ tracks for tracks,matched in zip(disconnected_components,mask) if matched ]\n",
    "    matched_particles = max_track_particle[mask]\n",
    "\n",
    "    \n",
    "    # 2.  tracking efficiency metric\n",
    "    \n",
    "    # get the total number of unique particles / true tracks : \n",
    "    num_particles = torch.sum( torch.unique(labels) != 0 )\n",
    "    # get the tracking efficiency : \n",
    "    tracking_efficiency = torch.sum( torch.unique(matched_particles)  != 0 )/num_particles\n",
    "    \n",
    "    # 3. tracking purity metric \n",
    "    \n",
    "    # get the total number of reconstructed tracks : \n",
    "    num_reconstucted_tracks = torch.sum( max_track_particle != 0 )\n",
    "    # get the tracking purity : \n",
    "    try : \n",
    "        tracking_purity= torch.sum( mask )/num_reconstucted_tracks\n",
    "    except ZeroDivisionError: \n",
    "        print('----No Reconstructed Track----')\n",
    "        tracking_purity = 0 \n",
    "    \n",
    "    # return the metrics : \n",
    "    \n",
    "    return {\n",
    "        'Tracking Efficiency' : tracking_efficiency, \n",
    "        'Tracking Purity' : tracking_purity \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tracking Efficiency': tensor(0.), 'Tracking Purity': tensor(0.)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_metric_dict = event_reconstruction_metrics( example_graph_data , labels  )\n",
    "example_metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = example_metric_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Define Train Test and Validation Dataloders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(\n",
    "    dataset:PointCloudData,\n",
    "    valid_size:float,\n",
    "    test_size:float,\n",
    "    num_works:int=0\n",
    "):\n",
    "    '''\n",
    "    valid_size : amount of data to reserve for validation (normalized to 1 )\n",
    "    test_size : amount of data to reserve for testing (normalized to 1 )\n",
    "    Returns : train/validation/test data loders. \n",
    "    '''\n",
    "    \n",
    "    train_size=1-test_size-valid_size\n",
    "    \n",
    "    if not ( (train_size <= 1.) & (valid_size <= 1.) & (test_size <= 1. )) : \n",
    "        raise ValueError('Improper valid/train size encountered.')\n",
    "    \n",
    "    # total number of events : \n",
    "    num_events = len(dataset)\n",
    "    \n",
    "    # get shuffeled indices \n",
    "    indices = list(range(num_events))\n",
    "    np.random.shuffle(indices)\n",
    "    train_split = int(np.floor(train_size * num_events))\n",
    "    valid_split = int(np.floor(valid_size * num_events))\n",
    "    \n",
    "    train_index, valid_index, test_index = indices[0:train_split], indices[train_split:train_split + valid_split], indices[train_split + valid_split:]\n",
    "    \n",
    "    # define samplers for obtaining training and validation batches\n",
    "    train_sampler = SubsetRandomSampler(train_index)\n",
    "    valid_sampler = SubsetRandomSampler(valid_index)\n",
    "    test_sampler = SubsetRandomSampler(test_index)\n",
    "    \n",
    "    # define data loaders : \n",
    "    train_loder = DataLoader(\n",
    "        dataset=dataset, \n",
    "        batch_size=1, \n",
    "        num_workers=num_works, \n",
    "        sampler = train_sampler,\n",
    "        collate_fn=collate_function\n",
    "    )\n",
    "    \n",
    "    valid_loder = DataLoader(\n",
    "        dataset=dataset, \n",
    "        batch_size=1, \n",
    "        num_workers=num_works, \n",
    "        sampler = valid_sampler,\n",
    "        collate_fn=collate_function\n",
    "    )\n",
    "    \n",
    "    test_loder = DataLoader(\n",
    "        dataset=dataset, \n",
    "        batch_size=1, \n",
    "        num_workers=num_works, \n",
    "        sampler = test_sampler,\n",
    "        collate_fn=collate_function\n",
    "    )\n",
    "    \n",
    "    # return data loders : \n",
    "    return train_loder,valid_loder,test_loder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Training and Testing \n",
    "\n",
    "here we intend to define the training and testing flow of the algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainEmbedding(\n",
    "    model:EmbeddingModel,\n",
    "    train_loder:DataLoader, \n",
    "    lr:float=0.01,\n",
    "    margin:float=1,\n",
    "    max_num_neighbors:int=12\n",
    "): \n",
    "    # initialize optimizer : \n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr = lr)\n",
    "    \n",
    "    # initialize train loss\n",
    "    train_loss = 0.0 \n",
    "    \n",
    "    # total number of events : \n",
    "    num_events = len(train_loder)\n",
    "    \n",
    "    # loop  over the training dataset \n",
    "    for i,(event_data,labels) in tqdm(enumerate(train_loder), bar_format='{l_bar}{bar}| Event {n_fmt}/{total_fmt} [{elapsed}<{remaining}, ' '{rate_fmt}{postfix}]' , total = len(train_loder) , ncols = 75) : \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(event_data.squeeze_(dim=0))\n",
    "        \n",
    "        radius_graph_edge_index = torch_geometric.nn.pool.radius_graph(\n",
    "            output, \n",
    "            r = margin , \n",
    "            loop = False , \n",
    "            max_num_neighbors=max_num_neighbors\n",
    "        )\n",
    "        \n",
    "        loss = EmbeddingLossFunction(\n",
    "            x = output,\n",
    "            labels=labels.squeeze_(dim=0),\n",
    "            radius_graph_edge_index=radius_graph_edge_index, \n",
    "            margin=margin\n",
    "        )\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    return train_loss/num_events\n",
    "\n",
    "\n",
    "def TestEmbedding(\n",
    "    model:EmbeddingModel, \n",
    "    test_loder:DataLoader, \n",
    "    margin:float=1, \n",
    "    max_num_neighbors:int=12\n",
    "):\n",
    "    # initialize loss , putity and efficiency \n",
    "    test_loss , test_track_efficiency , test_track_purity = 0.0 , 0.0 , 0.0 \n",
    "    \n",
    "    # get the number of events : \n",
    "    num_events = len(test_loder)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # loop  over the training dataset \n",
    "    for i,(event_data,labels) in tqdm(enumerate(test_loder), bar_format='{l_bar}{bar}| Event {n_fmt}/{total_fmt} [{elapsed}<{remaining}, ' '{rate_fmt}{postfix}]' , total = len(test_loder) , ncols = 75 ) :  \n",
    "        \n",
    "        output = model(event_data.squeeze_(dim=0))\n",
    "        \n",
    "        # radius graph edges \n",
    "        radius_graph_edge_index = torch_geometric.nn.pool.radius_graph(\n",
    "            output, \n",
    "            r = margin , \n",
    "            loop = False , \n",
    "            max_num_neighbors=max_num_neighbors\n",
    "        )\n",
    "        \n",
    "        # get the loss : \n",
    "        loss = EmbeddingLossFunction(\n",
    "            x = output, \n",
    "            labels = labels.squeeze_(dim=0),\n",
    "            radius_graph_edge_index=radius_graph_edge_index, \n",
    "            margin=margin\n",
    "        )\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # create the graph data structure : \n",
    "        event_graph_data = Data(\n",
    "            x = event_data, \n",
    "            edge_index=radius_graph_edge_index, \n",
    "            y = labels\n",
    "        )\n",
    "        \n",
    "        # get the track performance metrics : \n",
    "        efficiency , purity = event_reconstruction_metrics(event_graph_data, labels ).values()\n",
    "        test_track_efficiency += efficiency.item() \n",
    "        test_track_purity += purity.item()\n",
    "        \n",
    "    return test_loss/num_events , test_track_efficiency/num_events , test_track_purity/num_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a training loop for a given number of epoch's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainEmbeddingModel(\n",
    "    model:EmbeddingModel, \n",
    "    train_loder:DataLoader, \n",
    "    valid_loder:DataLoader, \n",
    "    lr:float=0.01,\n",
    "    margin:float=1, \n",
    "    max_num_neighbors:int=12,\n",
    "    n_epochs:int=15, \n",
    "    save_model:bool=True, \n",
    "    save_model_path:str=None\n",
    "): \n",
    "    if save_model and save_model_path==None: \n",
    "        raise ValueError('Must pass a valid path to save the model.')\n",
    "    \n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.inf \n",
    "    # initialize tracker for validation metrices and losses \n",
    "    train_loss , valid_loss , valid_track_efficiency , valid_track_purity = [] , [] , [] , []\n",
    "    \n",
    "    # loop throuth the training process n_epoch times \n",
    "    for epoch in range(1,n_epochs+1):\n",
    "        \n",
    "        print(f'----------------------Starting Epoch {epoch}----------------------')\n",
    "        \n",
    "        print('Begin Training: ')\n",
    "        # training step : \n",
    "        train_loss.append(\n",
    "            TrainEmbedding(\n",
    "                model=model, \n",
    "                train_loder=train_loder, \n",
    "                lr = lr , \n",
    "                margin = margin , \n",
    "                max_num_neighbors=max_num_neighbors\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        print('Begin Validation: ')\n",
    "        # validation step : \n",
    "        (\n",
    "            epoch_valid_loss, \n",
    "            epoch_valid_track_efficiency, \n",
    "            epoch_valid_track_purity\n",
    "        ) = TestEmbedding(\n",
    "            model = model , \n",
    "            test_loder= valid_loder, \n",
    "            margin = margin , \n",
    "            max_num_neighbors=max_num_neighbors\n",
    "        )\n",
    "        valid_loss.append(epoch_valid_loss)\n",
    "        valid_track_efficiency.append(epoch_valid_track_efficiency)\n",
    "        valid_track_purity.append(epoch_valid_track_purity)\n",
    "        \n",
    "        print('Epoch: {} \\nTraining Loss: {:.6f} \\nValidation Loss: {:.6f} \\nTracking Efficiency: {:.6f} \\nTracking Purity: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss[-1],\n",
    "            valid_loss[-1],\n",
    "            valid_track_efficiency[-1], \n",
    "            valid_track_purity[-1]\n",
    "        ))\n",
    "    \n",
    "        # save model if validation loss has decreased\n",
    "        if valid_loss[-1] <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss[-1]\n",
    "            ))\n",
    "            torch.save(model.state_dict(), save_model_path)\n",
    "            valid_loss_min = valid_loss[-1]  \n",
    "    \n",
    "    return (\n",
    "        list(range(1,n_epochs+1)),\n",
    "        train_loss, \n",
    "        valid_loss, \n",
    "        valid_track_efficiency, \n",
    "        valid_track_purity\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Embedding Model Tranining : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120246, 5])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.BatchNorm1d(5)( example_model_out).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Starting Epoch 1----------------------\n",
      "Begin Training: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| Event 70/70 [16:05<00:00, 13.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| Event 20/20 [05:42<00:00, 17.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "Training Loss: 658947.108929 \n",
      "Validation Loss: 646925.964063 \n",
      "Tracking Efficiency: 0.000000 \n",
      "Tracking Purity: 0.000000\n",
      "Validation loss decreased (inf --> 646925.964063).  Saving model ...\n",
      "----------------------Starting Epoch 2----------------------\n",
      "Begin Training: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| Event 70/70 [19:19<00:00, 16.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| Event 20/20 [07:10<00:00, 21.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \n",
      "Training Loss: 625822.967411 \n",
      "Validation Loss: 620946.143750 \n",
      "Tracking Efficiency: 0.000000 \n",
      "Tracking Purity: 0.000000\n",
      "Validation loss decreased (646925.964063 --> 620946.143750).  Saving model ...\n",
      "----------------------Starting Epoch 3----------------------\n",
      "Begin Training: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████████████████████▎        | Event 51/70 [17:16<08:14, 26.02s/it]"
     ]
    }
   ],
   "source": [
    "# get the point cloud data \n",
    "event_dataset = PointCloudData(\n",
    "    dataset_path='../data/train_100_events/',\n",
    "    detector_path='../data/detectors.csv'\n",
    ")\n",
    "\n",
    "# get the data loders : \n",
    "(\n",
    "    train_loder, \n",
    "    valid_loder, \n",
    "    test_loder\n",
    ") = train_test_split(\n",
    "    dataset=event_dataset,\n",
    "    valid_size=0.2, \n",
    "    test_size=0.1\n",
    ")\n",
    "\n",
    "# initialize the model : \n",
    "embedding_model = EmbeddingModel(\n",
    "    in_features=15, \n",
    "    hidden_features=[20,25,15,10],\n",
    "    out_features=5\n",
    ")\n",
    "\n",
    "save_model_path = '../data/models/embedding_model.pt'\n",
    "\n",
    "# train the model : \n",
    "(\n",
    "    epochs , train_loss , \n",
    "    valid_loss , valid_efficiency, \n",
    "    valid_purity \n",
    ") = TrainEmbeddingModel(\n",
    "    model = embedding_model, \n",
    "    train_loder=train_loder, \n",
    "    valid_loder=valid_loder, \n",
    "    save_model_path=save_model_path, \n",
    "    margin = 0.1 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mepochs\u001b[49m, train_loss , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo-\u001b[39m\u001b[38;5;124m'\u001b[39m , label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m )\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs, valid_loss , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo-\u001b[39m\u001b[38;5;124m'\u001b[39m , label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mgrid()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(epochs, train_loss , 'o-' , label = 'Train Loss' )\n",
    "plt.plot(epochs, valid_loss , 'o-' , label = 'Validation Loss')\n",
    "plt.grid()\n",
    "plt.title('Train and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, valid_purity , 'o-' )\n",
    "plt.grid()\n",
    "plt.title('Purity on Validation Set')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Purity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, valid_efficiency , 'o-'  )\n",
    "plt.grid()\n",
    "plt.title('Efficiency on Validation Set')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Efficiency')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TrackMLVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
