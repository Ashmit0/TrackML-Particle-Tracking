{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Model and The Dataset Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we develop the next step in our GNN model. To apply either the _meta-layer_ approch or the  or the _ParticleNet_ approch we need to first have a graph structure in hand. \n",
    "\n",
    "Comming up with direct mehods to make a graph structure from the processed event data is not encouraged, considering the huge number of hits / nodes ($\\approx 10^6$). Direct method's like compaeing distances and angles are computatinally expensive. Insted we train a multylayer perceptron (MLP) in such a way so that points belonging to the same track are close in the latent space, which will allow us to apply a effective knn algorithm to construct the graph strcuture. \n",
    "This intermidiate ML model is reffered to as the embeddding model. [1]\n",
    "\n",
    "[1] : Ju, Xiangyang, et al. \"Performance of a geometric deep learning pipeline for HL-LHC particle tracking.\" The European Physical Journal C 81 (2021): 1-14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.6.0\n",
      "PyG version 2.6.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import ortho_group\n",
    "\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.linalg import norm \n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, ReLU, BatchNorm1d, Module, Sequential\n",
    "from torch import Tensor\n",
    "\n",
    "# torch.set_default_dtype(torch.float64)\n",
    "\n",
    "from torch_geometric.typing import (\n",
    "    Adj,\n",
    "    OptPairTensor,\n",
    "    OptTensor,\n",
    "    Size,\n",
    "    SparseTensor,\n",
    "    torch_sparse,\n",
    ")\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Batch\n",
    "import torch_geometric.transforms as T\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch_geometric.utils import remove_self_loops, to_dense_adj, dense_to_sparse, is_undirected , to_undirected, contains_self_loops , to_networkx\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool, knn_graph\n",
    "from torch_geometric.datasets import QM9\n",
    "# from torch_scatter import scatter\n",
    "# from torch_cluster import knn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "# import uproot\n",
    "import vector\n",
    "vector.register_awkward()\n",
    "import awkward as ak\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 5 \n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrackML import Preprocessing\n",
    "from TrackML.Models.utils import buildMLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set default params for matplotlib : \n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define Point Cloud Class for Processed Data \n",
    "We define a point cloud dataset class to train our embedding model with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_path = '../data/detectors.csv'\n",
    "dataset_path = '../data/train_100_events/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudData(data.Dataset): \n",
    "    \n",
    "    # initialize the dataset class : \n",
    "    def __init__(self,dataset_path:str,detector_path:str,min_nhits=3)->None:\n",
    "        '''\n",
    "        dataset_path : path to the dataset with the events. \n",
    "        eventids : list of eventid identifiers. \n",
    "        '''\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dataset_path = dataset_path\n",
    "        self.min_nhits = min_nhits \n",
    "        \n",
    "        \n",
    "        self.detector = Preprocessing.load_detector_data(detector_path) \n",
    "        \n",
    "        # get the list of event ids from the dataset folder : \n",
    "        eventids = [ code[:-9] for code in os.listdir(dataset_path) if code.endswith('-hits.csv') ]\n",
    "        self.eventids = eventids\n",
    "        \n",
    "        \n",
    "    def __len__(self)->int: \n",
    "        return len( self.eventids )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            Preprocessing.process_event_data(\n",
    "                train_path=self.dataset_path, \n",
    "                eventid=self.eventids[index], \n",
    "                detector=self.detector\n",
    "            ), \n",
    "            Preprocessing.process_particle_labels(\n",
    "                train_path=self.dataset_path, \n",
    "                eventid=self.eventids[index], \n",
    "                min_nhits=self.min_nhits \n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_cloud_dataset = PointCloudData(dataset_path,detector_path)\n",
    "len(point_cloud_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_function(data_list): \n",
    "    return data_list[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the data loader object ! \n",
    "point_clout_data_loder = data.DataLoader(\n",
    "    dataset=point_cloud_dataset, \n",
    "    batch_size=1, \n",
    "    shuffle=True ,\n",
    "    collate_fn=collate_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([120246, 15]), torch.Size([120246]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_feats , labels  = next(iter(point_clout_data_loder))\n",
    "node_feats.shape , labels.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create the Base Embedding Model.\n",
    "\n",
    "The model architecture is just a normal MLP with relu acctivation for hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModel(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features:int, \n",
    "        hidden_features:list, \n",
    "        out_features:int \n",
    "    )->None:\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # define the MLP layer : \n",
    "        self.MLP = buildMLP(\n",
    "            insize=in_features, \n",
    "            outsize=out_features, \n",
    "            features=hidden_features,\n",
    "            add_bnorm=True,\n",
    "            add_activation=nn.BatchNorm1d(out_features)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x:Tensor)->Tensor: \n",
    "        return self.MLP(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingModel(\n",
       "  (MLP): Sequential(\n",
       "    (0): Linear(in_features=15, out_features=20, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=20, out_features=25, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=25, out_features=15, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Linear(in_features=15, out_features=10, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Linear(in_features=10, out_features=5, bias=True)\n",
       "    (12): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_embedding_model = EmbeddingModel(\n",
    "    in_features=15, \n",
    "    hidden_features=[20,25,15,10],\n",
    "    out_features=5\n",
    ")\n",
    "example_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x13c008820>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_embedding_model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_feats.mean(dim=0 , keepdim=True).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120246, 15])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(node_feats/node_feats.std(dim=0 , keepdim=True)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120246, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_model_out = example_embedding_model(node_feats)\n",
    "example_model_out.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Latent Space Analysis \n",
    "\n",
    "Here we create a graph structure by using a _radius\\_graph_ algorithm, on the latent space featuers. We set the radius hyperparameter same as the margin for our pairwise hinge loss function (more on that later). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 402721])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margin = .01\n",
    "max_num_neighbors=12\n",
    "\n",
    "radius_graph_edge_index = torch_geometric.nn.pool.radius_graph(\n",
    "    example_model_out, \n",
    "    r = margin , \n",
    "    loop = False , \n",
    "    max_num_neighbors=max_num_neighbors\n",
    ")\n",
    "radius_graph_edge_index\n",
    "radius_graph_edge_index.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120246, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_model_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the graph is undirected \n",
    "is_undirected( radius_graph_edge_index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 461106])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the graph to a directed one \n",
    "radius_graph_edge_index = to_undirected( radius_graph_edge_index )\n",
    "radius_graph_edge_index.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now each pair had a duplicate copy in the indices list, \n",
    "# since the graph is undirected now. \n",
    "row , col = radius_graph_edge_index\n",
    "\n",
    "# Create a mask to get those pairs which have different \n",
    "# labels and avoid repeations by choosing row < col\n",
    "mask = ( row < col ) & ( labels[row] != labels[col] )\n",
    "\n",
    "negetive_pair_indices = radius_graph_edge_index[:,mask]\n",
    "del mask , row , col "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 223168])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negetive_pair_indices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create Custom Loss Function: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use pairwise hinge loss functions on all pairs of the hits. For this we use the Hinge Loss (`torch.nn.HingeEmbeddingLoss` see [documentation](https://pytorch.org/docs/stable/generated/torch.nn.HingeEmbeddingLoss.html#torch.nn.HingeEmbeddingLoss)). \n",
    "\n",
    "The loss function is given as: \n",
    "$$\n",
    "l_n = \\begin{cases}\n",
    "    x_n, &\\text{ if } y_n = 1 \\\\\n",
    "    max\\{0,\\text{margin}-x_n\\}, &\\text{ if } y_n = -1 \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Note that we cannot afford to calculate pairwise distance for all the hit pairs in the latent space, since that is computationally too expenceive. Insted we calculate the loss using a trick to optimize the calculation. \n",
    "\n",
    "We seperately calculate the loss for all the correct hit pairs and calculate the loss for all the incorrect hit pairs that are formed post a knn cluster calculation. This way we avoid the redundent zeros that come up in direct pairwise loss calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pair_indices = Preprocessing.get_track_index_pairs(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 538549]), torch.Size([2, 223168]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_pair_indices.shape , negetive_pair_indices.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4786, 1.1246, 1.7474,  ..., 0.2403, 0.2376, 0.0094],\n",
      "       grad_fn=<LinalgVectorNormBackward0>) tensor([0.0087, 0.0034, 0.0098,  ..., 0.0034, 0.0060, 0.0039],\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(989658.8125, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prow , pcol = positive_pair_indices  \n",
    "nrow , ncol = negetive_pair_indices\n",
    "\n",
    "# since the arry sizes are too large we apply batching for \n",
    "# pairwise distance calculations: \n",
    "\n",
    "loss_plus = norm(\n",
    "    example_model_out[prow , : ] - example_model_out[pcol, :] , \n",
    "    ord = 2 , \n",
    "    dim = -1 \n",
    ")\n",
    "\n",
    "loss_minus = norm(\n",
    "    example_model_out[ncol,:] - example_model_out[nrow,:], \n",
    "    ord = 2 , \n",
    "    dim = -1 \n",
    ")\n",
    "\n",
    "print( loss_plus , loss_minus )\n",
    "\n",
    "loss = (margin - loss_minus).sum() + loss_plus.sum()\n",
    "\n",
    "loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EmbeddingLossFunction(\n",
    "        x:Tensor,\n",
    "        labels:Tensor,\n",
    "        radius_graph_edge_index:Tensor,\n",
    "        margin:float=.01\n",
    "    )->Tensor: \n",
    "    '''\n",
    "    x  : model output in the latent space. shape = [nhits, out_feats]\n",
    "    radius_graph_edge_index : graph formed with the radius ball algorithm. \n",
    "    positive_idx : pairs of indices of hits sharing the same \n",
    "        particle id. shape = [2,num_positive_pairs]. \n",
    "    negetive_idx : pairs of hits indices within the latent space \n",
    "        margin radius ball having different particle ids. \n",
    "    returns : the pair wise hinge loss. \n",
    "    '''\n",
    "    \n",
    "    radius_graph_edge_index = to_undirected( radius_graph_edge_index )\n",
    "    \n",
    "    # get the positive indices \n",
    "    positive_idx = Preprocessing.get_track_index_pairs(labels)\n",
    "    \n",
    "    # get the negetive indices pairs that lie within the margin ball : \n",
    "    row , col = radius_graph_edge_index\n",
    "\n",
    "    # Create a mask to get those pairs which have different \n",
    "    # labels and avoid repeations by choosing row < col\n",
    "    mask = ( row < col ) & ( labels[row] != labels[col] )\n",
    "    negetive_idx = radius_graph_edge_index[:,mask]\n",
    "    \n",
    "    # get the positive row and col idx : \n",
    "    prow , pcol = positive_idx \n",
    "    \n",
    "    # get the negetive row and col idx : \n",
    "    nrow , ncol = negetive_idx\n",
    "    \n",
    "    # delete variables not in use : \n",
    "    del positive_idx  , negetive_idx , radius_graph_edge_index\n",
    "    \n",
    "    # loss form the positive pairs \n",
    "    loss_plus = norm(\n",
    "    x[prow , : ] - x[pcol, :] , \n",
    "    ord = 2 , \n",
    "    dim = -1 \n",
    "    )\n",
    "\n",
    "    # distance between negetive pairs that lie within the margin\n",
    "    loss_minus = norm(\n",
    "        x[ncol,:] - x[nrow,:], \n",
    "        ord = 2 , \n",
    "        dim = -1 \n",
    "    )\n",
    "    \n",
    "    del pcol , ncol , prow , ncol , x \n",
    "    \n",
    "    foo1 = (margin - loss_minus).sum()\n",
    "    foo2 = loss_plus.sum()\n",
    "    # final loss \n",
    "    loss = torch.log(foo1) + torch.log(1 + foo2/foo1 )\n",
    "\n",
    "    return loss     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Define Graph Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use knn statergy in the latent space to create graph structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_graph_structure(latent_space_hits:Tensor,k:int): \n",
    "#     return torch_geometric.nn.pool.knn_graph(x = latent_space_hits, k = k )\n",
    "\n",
    "# k=5 \n",
    "# example_edge_indeces = create_graph_structure(example_model_out,k=k)\n",
    "# example_edge_indeces.shape \n",
    "\n",
    "# get PyG grapg data structure for the knn buil graph. \n",
    "example_graph_data = Data(\n",
    "    x = node_feats, \n",
    "    edge_index=radius_graph_edge_index, \n",
    "    y = labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "from networkx import connected_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disconnected_components(data:Data):\n",
    "    # Convert PyG graph to NetworkX graph\n",
    "    G = to_networkx(data, to_undirected=True)\n",
    "    \n",
    "    # Get connected components\n",
    "    component_list = list(connected_components(G))\n",
    "    \n",
    "    # Convert node indices back to PyTorch tensors\n",
    "    components = [torch.tensor(list(component)) for component in component_list]\n",
    "    \n",
    "    return components\n",
    "\n",
    "example_components = get_disconnected_components(example_graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60676, torch.Size([9388]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( example_components ),torch.unique(labels).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(288251816628453376), tensor(0))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get one of these component for metric analysis \n",
    "example_component = example_components[0]\n",
    "print(example_component.shape)\n",
    "\n",
    "# find the majority particle id that belong to this track: \n",
    "component_labels = labels[example_component]\n",
    "mode , count = torch.mode( component_labels )\n",
    "mode , count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60676, 60676)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accociateed particle with each disconnectde component of the graph : \n",
    "accociated_particle = [ torch.mode(labels[component])[0] for component in example_components]\n",
    "len(accociated_particle) , len(example_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Define Track Metrics\n",
    "\n",
    "for detais of the metrices used, see [1]. \n",
    "\n",
    "[1] Ju, Xiangyang, et al. \"Performance of a geometric deep learning pipeline for HL-LHC particle tracking.\" The European Physical Journal C 81 (2021): page 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_reconstruction_metrics( graph_data:Data , labels:Tensor )->tuple: \n",
    "    '''\n",
    "        data : graph dataset to get the metrics for : \n",
    "        labels : particle_ids for each of the nodes (hits)\n",
    "        returns : the trajecteory and particle purity of the graph dataset. \n",
    "    '''\n",
    "    \n",
    "    # get the disconnected compoenents (reconstructed tracks) form the graph steructure : \n",
    "    disconnected_components = get_disconnected_components(graph_data)\n",
    "    \n",
    "    # del graph_data \n",
    "    ## 1. get the matched partices for each of the disconnecte graphs : \n",
    "    \n",
    "    #  partices with the max occourence for each of the disconnected components : \n",
    "    max_track_particle = torch.tensor([ torch.mode(labels[component])[0] for component in disconnected_components])\n",
    "    # print( max_track_particle )\n",
    "    # frequency of the particle with the most occourence for each of the disconnected component : \n",
    "    max_track_particle_freq = torch.tensor([ torch.sum(labels[track] == particle) for particle,track in zip(max_track_particle,disconnected_components)])\n",
    "    # print( max_track_particle_freq )\n",
    "    # get the number of hits that belong to each reconstructed track : \n",
    "    num_hits_tracks = torch.tensor( [component.shape[0] for component in disconnected_components] )\n",
    "    # print( num_hits_tracks )\n",
    "    # keep mark for each reconstructed track for which the particle \n",
    "    # with the most occourance, makes for at least 50% of all the hits in \n",
    "    # the given reconstructed track. \n",
    "    # we also exclude particle's with id 0 \n",
    "    \n",
    "    mask = ( 2*max_track_particle_freq >= num_hits_tracks ) & ( max_track_particle != 0 )\n",
    "    \n",
    "    # total number of true hits left by the underlying max_track_particle : \n",
    "    max_track_particle_num_true_hits = torch.tensor([torch.sum(labels==particle) for particle in max_track_particle])\n",
    "    \n",
    "    # update the mark, now slelecting the tracks such that at\n",
    "    # least 50% of the max occurance particles true hits\n",
    "    # must be contained in the reconstructed graph. \n",
    "    mask = mask & ( 2*max_track_particle_freq >= max_track_particle_num_true_hits )\n",
    "    \n",
    "    # print(f'Toal Number of Matched Particles : {torch.sum(mask)}' )\n",
    "    \n",
    "    # with this we can how get the matched reconstructed \n",
    "    # tracks and corresponding matched particles \n",
    "    matched_tracks = [ tracks for tracks,matched in zip(disconnected_components,mask) if matched ]\n",
    "    matched_particles = max_track_particle[mask]\n",
    "\n",
    "\n",
    "    # 2. Get the Track Purity : \n",
    "    track_purity  = torch.mean(max_track_particle_freq/num_hits_tracks)\n",
    "    # print( max_track_particle_freq/num_hits_tracks ) \n",
    "    # 3. Get Particle Purity : \n",
    "    particle_purity = torch.mean(max_track_particle_freq/max_track_particle_num_true_hits)\n",
    "    # print( max_track_particle_freq/max_track_particle_num_true_hits )\n",
    "    \n",
    "    # # # 2.  tracking efficiency metric\n",
    "    \n",
    "    # # get the total number of unique particles / true tracks : \n",
    "    # num_particles = torch.sum( torch.unique(labels) != 0 )\n",
    "    # # get the tracking efficiency : \n",
    "    # tracking_efficiency = torch.sum( torch.unique(matched_particles)  != 0 )/num_particles\n",
    "    \n",
    "    # # # 3. tracking purity metric \n",
    "    \n",
    "    # # get the total number of reconstructed tracks : \n",
    "    # num_reconstucted_tracks = torch.sum( max_track_particle != 0 )\n",
    "    # # get the tracking purity : \n",
    "    # if num_reconstucted_tracks == 0 : \n",
    "    #     tracking_purity = torch.tensor([0.0])\n",
    "    # else : \n",
    "    #     tracking_purity = torch.sum(mask)/num_reconstucted_tracks\n",
    "    \n",
    "    # # return the metrics : \n",
    "    \n",
    "    return  track_purity , particle_purity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9091), tensor(0.0749))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_reconstruction_metrics( example_graph_data , labels )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Define Train Test and Validation Dataloders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(\n",
    "    dataset:PointCloudData,\n",
    "    valid_size:float,\n",
    "    test_size:float,\n",
    "    num_works:int=4\n",
    "):\n",
    "    '''\n",
    "    valid_size : amount of data to reserve for validation (normalized to 1 )\n",
    "    test_size : amount of data to reserve for testing (normalized to 1 )\n",
    "    Returns : train/validation/test data loders. \n",
    "    '''\n",
    "    \n",
    "    train_size=1-test_size-valid_size\n",
    "    \n",
    "    if not ( (train_size <= 1.) & (valid_size <= 1.) & (test_size <= 1. )) : \n",
    "        raise ValueError('Improper valid/train size encountered.')\n",
    "    \n",
    "    # total number of events : \n",
    "    num_events = len(dataset)\n",
    "    \n",
    "    # get shuffeled indices \n",
    "    indices = list(range(num_events))\n",
    "    np.random.shuffle(indices)\n",
    "    train_split = int(np.floor(train_size * num_events))\n",
    "    valid_split = int(np.floor(valid_size * num_events))\n",
    "    \n",
    "    train_index, valid_index, test_index = indices[0:train_split], indices[train_split:train_split + valid_split], indices[train_split + valid_split:]\n",
    "    \n",
    "    # define samplers for obtaining training and validation batches\n",
    "    train_sampler = SubsetRandomSampler(train_index)\n",
    "    valid_sampler = SubsetRandomSampler(valid_index)\n",
    "    test_sampler = SubsetRandomSampler(test_index)\n",
    "    \n",
    "    # define data loaders : \n",
    "    train_loder = DataLoader(\n",
    "        dataset=dataset, \n",
    "        batch_size=1, \n",
    "        num_workers=num_works, \n",
    "        sampler = train_sampler,\n",
    "        persistent_workers=True if num_works > 0 else False\n",
    "    )\n",
    "    \n",
    "    valid_loder = DataLoader(\n",
    "        dataset=dataset, \n",
    "        batch_size=1, \n",
    "        num_workers=num_works, \n",
    "        sampler = valid_sampler,\n",
    "        persistent_workers=True if num_works > 0 else False\n",
    "    )\n",
    "    \n",
    "    test_loder = DataLoader(\n",
    "        dataset=dataset, \n",
    "        batch_size=1, \n",
    "        num_workers=num_works, \n",
    "        sampler = test_sampler,\n",
    "        persistent_workers=True if num_works > 0 else False\n",
    "    )\n",
    "    \n",
    "    # return data loders : \n",
    "    return train_loder,valid_loder,test_loder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Training and Testing \n",
    "\n",
    "here we intend to define the training and testing flow of the algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainEmbedding(\n",
    "    model:EmbeddingModel,\n",
    "    train_loder:DataLoader, \n",
    "    lr:float=0.01,\n",
    "    margin:float=0.01,\n",
    "    max_num_neighbors:int=100\n",
    "): \n",
    "    \n",
    "    # initialize optimizer : \n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr = lr)\n",
    "    \n",
    "    # initialize train loss\n",
    "    train_loss = 0.0 \n",
    "    \n",
    "    # total number of events : \n",
    "    num_events = len(train_loder)\n",
    "    \n",
    "    # loop  over the training dataset \n",
    "    for i,(event_data,labels) in tqdm(enumerate(train_loder), bar_format='{l_bar}{bar}| Event {n_fmt}/{total_fmt} [{elapsed}<{remaining}, ' '{rate_fmt}{postfix}]' , total = len(train_loder) , ncols = 75) : \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(event_data.squeeze_(dim=0))\n",
    "        \n",
    "        radius_graph_edge_index = torch_geometric.nn.pool.radius_graph(\n",
    "            output, \n",
    "            r = margin , \n",
    "            loop = False , \n",
    "            max_num_neighbors=max_num_neighbors\n",
    "        )\n",
    "        \n",
    "        loss = EmbeddingLossFunction(\n",
    "            x = output,\n",
    "            labels=labels.squeeze_(dim=0),\n",
    "            radius_graph_edge_index=radius_graph_edge_index, \n",
    "            margin=margin\n",
    "        )\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    model.to('cpu')\n",
    "        \n",
    "    return train_loss/num_events\n",
    "\n",
    "\n",
    "def TestEmbedding(\n",
    "    model:EmbeddingModel, \n",
    "    test_loder:DataLoader, \n",
    "    margin:float=0.01, \n",
    "    max_num_neighbors:int=100\n",
    "):\n",
    "    # initialize loss , putity and efficiency \n",
    "    test_loss , test_track_efficiency , test_track_purity = 0.0 , 0.0 , 0.0 \n",
    "    \n",
    "    # get the number of events : \n",
    "    num_events = len(test_loder)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # loop  over the training dataset \n",
    "    for i,(event_data,labels) in tqdm(enumerate(test_loder), bar_format='{l_bar}{bar}| Event {n_fmt}/{total_fmt} [{elapsed}<{remaining}, ' '{rate_fmt}{postfix}]' , total = len(test_loder) , ncols = 75 ) :  \n",
    "        \n",
    "        output = model(event_data.squeeze_(dim=0))\n",
    "        \n",
    "        # radius graph edges \n",
    "        radius_graph_edge_index = torch_geometric.nn.pool.radius_graph(\n",
    "            output, \n",
    "            r = margin , \n",
    "            loop = False , \n",
    "            max_num_neighbors=max_num_neighbors\n",
    "        )\n",
    "        \n",
    "        # get the loss : \n",
    "        loss = EmbeddingLossFunction(\n",
    "            x = output, \n",
    "            labels = labels.squeeze_(dim=0),\n",
    "            radius_graph_edge_index=radius_graph_edge_index, \n",
    "            margin=margin\n",
    "        )\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # create the graph data structure : \n",
    "        event_graph_data = Data(\n",
    "            x = event_data, \n",
    "            edge_index=radius_graph_edge_index, \n",
    "            y = labels\n",
    "        )\n",
    "        \n",
    "        # get the track performance metrics : \n",
    "        efficiency , purity = event_reconstruction_metrics(event_graph_data, labels )\n",
    "        test_track_efficiency += efficiency.item() \n",
    "        test_track_purity += purity.item()\n",
    "        \n",
    "    return test_loss/num_events , test_track_efficiency/num_events , test_track_purity/num_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a training loop for a given number of epoch's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainEmbeddingModel(\n",
    "    model:EmbeddingModel, \n",
    "    train_loder:DataLoader, \n",
    "    valid_loder:DataLoader, \n",
    "    lr:float=0.01,\n",
    "    margin:float=0.01, \n",
    "    max_num_neighbors:int=100,\n",
    "    n_epochs:int=15, \n",
    "    save_model:bool=True, \n",
    "    save_model_path:str=None\n",
    "): \n",
    "    if save_model and save_model_path==None: \n",
    "        raise ValueError('Must pass a valid path to save the model.')\n",
    "    \n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.inf \n",
    "    # initialize tracker for validation metrices and losses \n",
    "    train_loss , valid_loss , valid_track_efficiency , valid_track_purity = [] , [] , [] , []\n",
    "    \n",
    "    # loop throuth the training process n_epoch times \n",
    "    for epoch in range(1,n_epochs+1):\n",
    "        \n",
    "        print(f'----------------------Starting Epoch {epoch}----------------------')\n",
    "        \n",
    "        print('Begin Training: ')\n",
    "        # training step : \n",
    "        train_loss.append(\n",
    "            TrainEmbedding(\n",
    "                model=model, \n",
    "                train_loder=train_loder, \n",
    "                lr = lr , \n",
    "                margin = margin , \n",
    "                max_num_neighbors=max_num_neighbors\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        print('Begin Validation: ')\n",
    "        # validation step : \n",
    "        (\n",
    "            epoch_valid_loss, \n",
    "            epoch_valid_track_efficiency, \n",
    "            epoch_valid_track_purity\n",
    "        ) = TestEmbedding(\n",
    "            model = model , \n",
    "            test_loder= valid_loder, \n",
    "            margin = margin , \n",
    "            max_num_neighbors=max_num_neighbors\n",
    "        )\n",
    "        valid_loss.append(epoch_valid_loss)\n",
    "        valid_track_efficiency.append(epoch_valid_track_efficiency)\n",
    "        valid_track_purity.append(epoch_valid_track_purity)\n",
    "        \n",
    "        print('Training Loss: {:.6f} \\nValidation Loss: {:.6f} \\nTrack Purity: {:.6f} \\nParticle Purity: {:.6f}'.format(\n",
    "            train_loss[-1],\n",
    "            valid_loss[-1],\n",
    "            valid_track_efficiency[-1], \n",
    "            valid_track_purity[-1]\n",
    "        ))\n",
    "    \n",
    "        # save model if validation loss has decreased\n",
    "        if valid_loss[-1] <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss[-1]\n",
    "            ))\n",
    "            torch.save(model.state_dict(), save_model_path)\n",
    "            valid_loss_min = valid_loss[-1]  \n",
    "    \n",
    "    return (\n",
    "        list(range(1,n_epochs+1)),\n",
    "        train_loss, \n",
    "        valid_loss, \n",
    "        valid_track_efficiency, \n",
    "        valid_track_purity\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Example Running of the Model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120246, 5])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.BatchNorm1d(5)( example_model_out).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the point cloud data \n",
    "event_dataset = PointCloudData(\n",
    "    dataset_path='../data/train_100_events/',\n",
    "    detector_path='../data/detectors.csv'\n",
    ")\n",
    "\n",
    "# get the data loders : \n",
    "(\n",
    "    train_loder, \n",
    "    valid_loder, \n",
    "    test_loder\n",
    ") = train_test_split(\n",
    "    dataset=event_dataset,\n",
    "    valid_size=0.1, \n",
    "    test_size=0.1,\n",
    "    num_works=0\n",
    ")\n",
    "\n",
    "# initialize the model : \n",
    "embedding_model = EmbeddingModel(\n",
    "    in_features=15, \n",
    "    hidden_features=[1024,512,256,128,64,32,16],\n",
    "    out_features=5\n",
    ")\n",
    "\n",
    "save_model_path = '../data/models/embedding_model.pt'\n",
    "\n",
    "# # train the model : \n",
    "# (\n",
    "#     epochs , train_loss , \n",
    "#     valid_loss , valid_efficiency, \n",
    "#     valid_purity \n",
    "# ) = TrainEmbeddingModel(\n",
    "#     model = embedding_model, \n",
    "#     train_loder=train_loder, \n",
    "#     valid_loder=valid_loder, \n",
    "#     save_model_path=save_model_path, \n",
    "#     margin = 0.01 \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch_geometric.loader.dataloader.DataLoader at 0x138fcf4f0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(train_loder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 106942, 15])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = embedding_model(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Conver the pytorch model into a Pytorch Lightning Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule\n",
    "from torchmetrics import Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('03-Embedding-Hyperparameters.yml' , 'r' ) as f : \n",
    "    hparams = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from TrackML.Embedding.utils import EmbeddingModel,EmbeddingLossFunction,event_reconstruction_metrics,collate_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrackML.Embedding.utils import PointCloudData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type( hparams )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detector_path': '../data/detectors.csv',\n",
       " 'dataset_path': '../data/train_100_events/',\n",
       " 'min_hits': 3,\n",
       " 'shuffle': True,\n",
       " 'valid_size': 0.1,\n",
       " 'test_size': 0.1,\n",
       " 'num_works': 8,\n",
       " 'in_featuers': 15,\n",
       " 'hidden_featuers': [1024, 512, 256, 128, 64, 32, 16],\n",
       " 'out_featuers': 5,\n",
       " 'margin': 0.1,\n",
       " 'max_num_neighbours': 100,\n",
       " 'lr': 0.01,\n",
       " 'save_model': True,\n",
       " 'save_model_path': '../data/models/embedding_model.pt'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDataset(pl.LightningDataModule): \n",
    "    \n",
    "    # initialize the class : \n",
    "    def __init__(self,hparams)->None: \n",
    "        super().__init__() \n",
    "        self.save_hyperparameters(hparams)\n",
    "        \n",
    "    def prepare_data(self)->None: \n",
    "        self.detector = Preprocessing.load_detector_data(self.hparams['detector_path'])\n",
    "        # get the list of event ids from the dataset folder : \n",
    "        self.eventids = [ code[:-9] for code in os.listdir(self.hparams['dataset_path']) if code.endswith('-hits.csv') ]\n",
    "        dataset = PointCloudData(dataset_path=self.hparams['dataset_path'] , detector_path=self.hparams['detector_path'] , min_nhits=self.hparams['min_hits'] )\n",
    "        self.train_ds , self.val_ds , self.test_ds = train_test_split(\n",
    "            dataset=dataset, valid_size=self.hparams['valid_size'], \n",
    "            test_size=self.hparams['test_size'], num_works=self.hparams['num_works']\n",
    "        )\n",
    "    \n",
    "    def train_dataloader(self): \n",
    "        return self.train_ds \n",
    "    def val_dataloader(self): \n",
    "        return self.val_ds \n",
    "    def test_dataloader(self): \n",
    "        return self.test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom log loss metric for pytorch lightning : \n",
    "def _custom_dist_reduce_fn(x): \n",
    "    return torch.log( torch.sum( x , dim = 0 ) )\n",
    "\n",
    "class LogSumLoss(Metric):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add_state(\"log_loss_sum\", default=torch.tensor(0.0), dist_reduce_fx=_custom_dist_reduce_fn)\n",
    "\n",
    "    def update(self, loss):\n",
    "        self.log_loss_sum = torch.log(loss) + torch.log( 1 + torch.exp(self.log_loss_sum)/loss)\n",
    "\n",
    "    def compute(self):\n",
    "        return self.log_loss_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Purity(Metric):\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "        self.add_state(\n",
    "            'intersections', \n",
    "            default = torch.tensor([]), \n",
    "            dist_reduce_fx = 'cat'\n",
    "        )\n",
    "        self.add_state(\n",
    "            'num_hits', \n",
    "            default = torch.tensor([]),\n",
    "            dist_reduce_fx = 'cat'\n",
    "        )\n",
    "        \n",
    "    def update(self,intersections,num_hits):\n",
    "        self.intersections = intersections\n",
    "        self.num_hits = num_hits\n",
    "    \n",
    "    def compute(self): \n",
    "        return torch.mean( self.intersections/self.num_hits )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_reconstruction_metrics( graph_data:Data , labels:Tensor )->tuple: \n",
    "    '''\n",
    "        data : graph dataset to get the metrics for : \n",
    "        labels : particle_ids for each of the nodes (hits)\n",
    "        returns : the trajecteory and particle purity of the graph dataset. \n",
    "    '''\n",
    "    \n",
    "    # get the disconnected compoenents (reconstructed tracks) form the graph steructure : \n",
    "    disconnected_components = get_disconnected_components(graph_data)\n",
    "    \n",
    "    \n",
    "    ## 1. get the matched partices for each of the disconnecte graphs : \n",
    "    \n",
    "    #  partices with the max occourence for each of the disconnected components : \n",
    "    max_track_particle = torch.tensor([ torch.mode(labels[component])[0] for component in disconnected_components])\n",
    "    # print( max_track_particle )\n",
    "    # frequency of the particle with the most occourence for each of the disconnected component : \n",
    "    max_track_particle_freq = torch.tensor([ torch.sum(labels[track] == particle) for particle,track in zip(max_track_particle,disconnected_components)])\n",
    "    # print( max_track_particle_freq )\n",
    "    # get the number of hits that belong to each reconstructed track : \n",
    "    num_hits_tracks = torch.tensor( [component.shape[0] for component in disconnected_components] )\n",
    "    # total number of true hits left by the underlying max_track_particle : \n",
    "    max_track_particle_num_true_hits = torch.tensor([torch.sum(labels==particle) for particle in max_track_particle])\n",
    "    \n",
    "    return  max_track_particle_freq , num_hits_tracks , max_track_particle_num_true_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingBase(LightningModule):\n",
    "    \n",
    "    # initialize the Embedding Class \n",
    "    def __init__(self , hparams ): \n",
    "        super().__init__()\n",
    "        \n",
    "        # save the hypermeters : \n",
    "        self.save_hyperparameters(hparams)\n",
    "        \n",
    "        # loss accumulation metric : \n",
    "        self.log_sum_loss = LogSumLoss()\n",
    "        # track and particle purity : \n",
    "        self.particle_purity = Purity() \n",
    "        self.track_purity = Purity()\n",
    "        \n",
    "        # save the model descriptions : \n",
    "        self.model = EmbeddingModel(\n",
    "            in_features=hparams['in_featuers'] , \n",
    "            hidden_features=hparams['hidden_featuers'], \n",
    "            out_features=hparams['out_featuers']\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # forward function \n",
    "    def forward(self , inputs ): \n",
    "        return self.model( inputs )\n",
    "    \n",
    "    \n",
    "    # training logic : \n",
    "    def training_step(self , batch , batch_idx ): \n",
    "        \n",
    "        event_data , labels = batch \n",
    "        event_data.squeeze_(dim=0)\n",
    "        labels.squeeze_(dim=0)\n",
    "        \n",
    "        output = self( event_data )\n",
    "        \n",
    "        radius_graph_edge_index = torch_geometric.nn.pool.radius_graph(\n",
    "            output.to(device = 'cpu'), \n",
    "            r = self.hparams['margin'] , \n",
    "            loop = False , \n",
    "            max_num_neighbors=self.hparams['max_num_neighbours']\n",
    "        )\n",
    "        radius_graph_edge_index = radius_graph_edge_index.to( device = self.device )\n",
    "        loss = EmbeddingLossFunction(\n",
    "            x = output,\n",
    "            labels=labels.squeeze_(dim=0),\n",
    "            radius_graph_edge_index=radius_graph_edge_index, \n",
    "            margin=self.hparams['margin']\n",
    "        )\n",
    "        self.log(\n",
    "            'Loss' , loss, \n",
    "            prog_bar = True , on_step = True , on_epoch = False \n",
    "        )\n",
    "        \n",
    "        self.log_sum_loss.update(loss)\n",
    "        self.log(\n",
    "            'Log Loss' , self.log_sum_loss.compute(), on_step = False , \n",
    "            on_epoch = True , prog_bar = True , reduce_fx = 'max' \n",
    "        )\n",
    "        \n",
    "        self.log(\n",
    "            'Memory Allocated' , torch.mps.current_allocated_memory()/(1024**3), \n",
    "            prog_bar=True , on_step = True , on_epoch=True, \n",
    "            reduce_fx='max'\n",
    "        )\n",
    "        \n",
    "        return loss \n",
    "    \n",
    "    # common logic for test and validation \n",
    "    def _test_val_common_step_(self , batch , batch_idx ): \n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            event_data , labels = batch \n",
    "            event_data.squeeze_(dim=0)\n",
    "            labels.squeeze_(dim=0)\n",
    "            \n",
    "            output = self( event_data )\n",
    "            \n",
    "            radius_graph_edge_index = torch_geometric.nn.pool.radius_graph(\n",
    "                output.to(device = 'cpu'), \n",
    "                r = self.hparams['margin'] , \n",
    "                loop = False , \n",
    "                max_num_neighbors=self.hparams['max_num_neighbours']\n",
    "            )\n",
    "            # print(event_data.device)\n",
    "            radius_graph_edge_index = radius_graph_edge_index.to(event_data.device)\n",
    "            loss = EmbeddingLossFunction(\n",
    "                x = output,\n",
    "                labels=labels.squeeze_(dim=0),\n",
    "                radius_graph_edge_index=radius_graph_edge_index, \n",
    "                margin=self.hparams['margin']\n",
    "            )\n",
    "            self.log(\n",
    "                'Loss',loss, \n",
    "                prog_bar = True , \n",
    "                on_step = True , \n",
    "                on_epoch = False \n",
    "            )\n",
    "            self.log_sum_loss.update(loss)\n",
    "            self.log(\n",
    "                'Log Loss' , self.log_sum_loss.compute(), \n",
    "                on_step = False , on_epoch = True , \n",
    "                prog_bar = True , reduce_fx = 'max' \n",
    "            )\n",
    "            # create the graph data structure : \n",
    "            event_graph_data = Data(\n",
    "                x = event_data, \n",
    "                edge_index=radius_graph_edge_index, \n",
    "                y = labels\n",
    "            )\n",
    "            intersections , num_track , num_particle = event_reconstruction_metrics(event_graph_data,labels)\n",
    "            self.track_purity.update( intersections = intersections , num_hits = num_track )\n",
    "            self.particle_purity.update( intersections = intersections , num_hits = num_particle )\n",
    "            self.log_dict(\n",
    "                {'track purity' : self.track_purity.compute() , 'particle purity' : self.particle_purity.compute() }, \n",
    "                on_step = False , on_epoch = True , prog_bar = True , reduce_fx = 'mean'\n",
    "            )\n",
    "            self.log(\n",
    "                'Memory Allocated' , torch.mps.current_allocated_memory()/(1024**3), \n",
    "                prog_bar=True , on_step = True , on_epoch=True, \n",
    "                reduce_fx='max'\n",
    "            )\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        return self._test_val_common_step_(batch,batch_idx)\n",
    "    \n",
    "    def test_step(self,batch,batch_idx): \n",
    "        return self._test_val_common_step_(batch,batch_idx)\n",
    "    \n",
    "    # set the optimizer  :\n",
    "    def configure_optimizers(self): \n",
    "        return torch.optim.SGD(self.model.parameters(),lr = self.hparams['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/ashmitbathla/Documents/UGP-Local/TrackML/TrackMLVenv/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/ashmitbathla/Documents/UGP-Local/TrackML/TrackMLVenv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 3 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    }
   ],
   "source": [
    "model = EmbeddingBase(hparams)\n",
    "ds = EmbeddingDataset(hparams)\n",
    "\n",
    "from pytorch_lightning.callbacks import DeviceStatsMonitor\n",
    "device_stats = DeviceStatsMonitor()\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator = \"cpu\", \n",
    "    devices = \"auto\",\n",
    "    enable_checkpointing=True, \n",
    "    fast_dev_run = 3, \n",
    "    callbacks=[device_stats]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type           | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | log_sum_loss    | LogSumLoss     | 0      | train\n",
      "1 | particle_purity | Purity         | 0      | train\n",
      "2 | track_purity    | Purity         | 0      | train\n",
      "3 | model           | EmbeddingModel | 720 K  | train\n",
      "-----------------------------------------------------------\n",
      "720 K     Trainable params\n",
      "0         Non-trainable params\n",
      "720 K     Total params\n",
      "2.882     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6f6014428d48b3b5962cceec25ba51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0618e84668bf4bd8b34f09aecdbdf24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=3` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model , ds )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TrackMLVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
