{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Dataset \n",
    "We build a Pytorch Dataset Object to store and structure the graph data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries : \n",
    "import gc \n",
    "import os \n",
    "import random \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "# set random seed : \n",
    "np.random.seed( 41 )\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch import cdist\n",
    "from torch import Tensor \n",
    "import torch.functional as F \n",
    "import torch.utils.data as data \n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import dense_to_sparse , remove_self_loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if CPU is available for training : \n",
    "\n",
    "device = 'gpu'\n",
    "if torch.cuda.is_available(): \n",
    "    device = 'cuda'\n",
    "elif torch.mps.is_available(): \n",
    "    device = 'mps'\n",
    "\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Tensor( [ 1 , 2 ]  ).int()\n",
    "y = np.array( [ 1, 2 , 4 , 5 ])\n",
    "# y = Tensor( y )\n",
    "type(y[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Tensor([True , True , False ]) \n",
    "x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.],\n",
      "        [13.],\n",
      "        [25.]])\n",
      "tensor([[ 3.,  4.],\n",
      "        [12.,  5.],\n",
      "        [ 7., 24.]])\n",
      "tensor([[0.6000, 0.8000],\n",
      "        [0.9231, 0.3846],\n",
      "        [0.2800, 0.9600]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.],\n",
       "        [13.],\n",
       "        [25.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Tensor([\n",
    "    [3,4],\n",
    "    [12,5],\n",
    "    [7,24]\n",
    "])\n",
    "\n",
    "norm = torch.linalg.norm(x , ord=2 , dim = 1 , keepdim=True )\n",
    "\n",
    "print( norm )\n",
    "\n",
    "y = x/norm \n",
    "print( x )\n",
    "print( y ) \n",
    "\n",
    "torch.sum( x*y , dim = 1 , keepdim= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventData(data.Dataset): \n",
    "    \n",
    "    # initialaize the event dataset \n",
    "    def __init__(self,path:str,threshold_dist:float=40)->None:\n",
    "        '''\n",
    "        Inputs : \n",
    "            path: path to the folder where the csv file was contained.  \n",
    "        '''\n",
    "        super(EventData,self).__init__()\n",
    "        self.events = [code[:-9] for code in os.listdir(path) if code.endswith('-hits.csv')]\n",
    "        self.num_events = len(self.events)\n",
    "        self.threshold_dist  = threshold_dist\n",
    "        self.path = path \n",
    "        \n",
    "    # function returns graph type represntation of the event dataset \n",
    "    def GraphData(self,idx:int) -> Data :\n",
    "        eventid = self.events[idx] \n",
    "        \n",
    "        # read the required csv files : \n",
    "        hits = pd.read_csv(self.path+eventid+'-hits.csv')\n",
    "        truth = pd.read_csv(self.path+eventid+'-truth.csv')\n",
    "        cells = pd.read_csv(self.path+eventid+'-cells.csv')\n",
    "        \n",
    "        # total number of hits : these form the NODES of our graph. \n",
    "        nhits = hits.shape[0] \n",
    "        # x , y , z spatial featuers of the hits:  \n",
    "        hits_spatial = hits.to_numpy()[: , 1:4 ]\n",
    "        # Add a new feature vector : the number of cells that detect the hit : \n",
    "        node_fets = np.concatenate(\n",
    "            (\n",
    "                hits_spatial ,\n",
    "                cells.hit_id.value_counts().get( hits.hit_id , 0 ).to_numpy().reshape((-1,1))\n",
    "            ), \n",
    "            axis = 1 \n",
    "        )\n",
    "        # id's related to the hits \n",
    "        # this will help to initialize the graph structure : \n",
    "        hit_ids = hits.to_numpy(dtype = int)[: ,[0,*list(range(4,7))]]\n",
    "        \n",
    "        # get the particle true hit position and momentum, we add this to the node feat matrix : \n",
    "        node_fets = np.concatenate(\n",
    "            (\n",
    "                node_fets , \n",
    "                truth[['tx' , 'ty' , 'tz'  ]].to_numpy() - hits_spatial , \n",
    "                truth[['tpx' , 'tpy' ,'tpz']].to_numpy()\n",
    "            ), \n",
    "            axis = 1 \n",
    "        )\n",
    "        node_fets = Tensor( node_fets )\n",
    "        hits_spatial = Tensor( hits_spatial )\n",
    "        \n",
    "        # here we create edge_index's for the graph skeleton : \n",
    "        # First create a mask for ensuring the distance lying under 40 \n",
    "        # mask = cdist(hits_spatial , hits_spatial , p = 2 ) < self.threshold_dist  \n",
    "        # add constraint for volume_id : \n",
    "        volume_id = Tensor( hit_ids[: , 1 ] )\n",
    "        volume_mask = volume_id.unsqueeze(0) - volume_id.unsqueeze(1) > 0  \n",
    "        # add constraint for layer_id : \n",
    "        layer_id = Tensor( hit_ids[:,2] )\n",
    "        layer_mask = ( volume_id.unsqueeze(0) - volume_id.unsqueeze(1) == 0 ) & ( layer_id.unsqueeze(0) - layer_id.unsqueeze(1) >= 0 )\n",
    "        # merge the masks: \n",
    "        del volume_id , layer_id \n",
    "        gc.collect()\n",
    "        mask =  ( volume_mask | layer_mask ) # & mask \n",
    "        # create the adj matrix : \n",
    "        edge_index = mask.float() \n",
    "        del volume_mask , layer_mask , mask \n",
    "        gc.collect()\n",
    "        # create adj_index : \n",
    "        edge_index , _ = dense_to_sparse(edge_index) \n",
    "        # remove slef loop's from adj_index : \n",
    "        edge_index, _ = remove_self_loops(edge_index)\n",
    "        row , col = edge_index \n",
    "        \n",
    "        # number of edges : \n",
    "        num_edges = edge_index.shape[1]\n",
    "        \n",
    "        # create edge labels and edge attributes : \n",
    "        # Lables : \n",
    "            # label == 0 if the two nodes are not part of a traj \n",
    "            # label == 1 otherwise \n",
    "        edge_labels = ((truth.particle_id.to_numpy()[row] == truth.particle_id.to_numpy()[col]) & ( truth.particle_id.to_numpy()[row] != 0 ))\n",
    "        edge_labels = Tensor( edge_labels ).float()\n",
    "        \n",
    "        # Attributes : \n",
    "            # Angle: between the momentum vector of the particle and the displacement vector between the hits. \n",
    "            # Distance: euclidean distance between the two hits. \n",
    "        pVector = Tensor( truth[['tpx' , 'tpy' ,'tpz']].to_numpy()[row] )\n",
    "        pVector = pVector/torch.linalg.norm( pVector , ord = 2 , dim = 1 , keepdim= True )\n",
    "        disp = Tensor( hits[['x','y','z']].to_numpy()[row] -  hits[['x','y','z']].to_numpy()[col] )\n",
    "        dist = torch.linalg.norm( disp , ord = 2 , dim = 1 , keepdim=True )\n",
    "        angle = torch.sum( pVector*(disp/dist) , dim = 1 , keepdim=True )\n",
    "        angle[torch.isnan(angle)] = 0.\n",
    "        del pVector , disp  \n",
    "        gc.collect()\n",
    "        edge_attr = torch.cat([angle , dist] , dim = 1 )\n",
    "        del angle , dist \n",
    "        gc.collect()\n",
    "        \n",
    "        # define graph data : \n",
    "        graph_data = Data(\n",
    "            x = node_fets , \n",
    "            edge_index=edge_index , \n",
    "            edge_attr = edge_attr , \n",
    "            label = edge_labels , \n",
    "            num_nodes = nhits , \n",
    "            num_edges = num_edges \n",
    "        )\n",
    "        \n",
    "        return graph_data \n",
    "    \n",
    "    def __len__(self)->int: \n",
    "        return self.num_events \n",
    "    \n",
    "    def __getitem__(self,index:int)->Data:\n",
    "        return self.GraphData(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# test event data code : \n",
    "dataset = EventData(path='../data/train_100_events/')\n",
    "size = len( dataset )\n",
    "size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnum = np.random.choice(np.arange(size))\n",
    "random_event = dataset[rnum]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VirtualEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
